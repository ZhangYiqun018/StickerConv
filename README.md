# StickerConv: Generating Multimodal Empathetic Responses from Scratch

<a href='https://neu-datamining.github.io/StickerConv/'><img src='https://img.shields.io/badge/Project-Page-Green'></a> <a href='https://arxiv.org/abs/2402.01679'><img src='https://img.shields.io/badge/Paper-Arxiv-red'></a>  <a href='https://huggingface.co/datasets/NEUDM/StickerConv'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Dataset-blue'></a>

## Update

- **2024-05-16:** Our paper is accepted by **ACL 2024 Main**! ðŸŽ‰
- **2024-02-16:** Submission version.
- **2024-01-20:** Ongoing work.

## :four_leaf_clover: Overview

<p align="center">
<img src="./figure/Agent4SC.png" width=650>
</p>
<p align="center">
    <font face="Times New Roman", colo=grey>The overview of Agent4SC.
</p>

<p align="center">
<img src="./figure/PEGS.png" width=650>
</p>
<p align="center">
    <font face="Times New Roman", colo=grey>The architecture of PEGS framework.
</p>

## :atom_symbol: StickerConv Dataset
<p align="center">
<img src="figure/StickerConv_example.png" width=300>
</p>

<p align="center"><font face="Times New Roman">An example of multimodal conversation in our StickerConv dataset.
</p>

## :computer: Case Study

<p align="center">
<img src="figure/case_study_conversation.png" width=500>
</p>
<p align="center"><font face="Times New Roman">Examples of conversations by users interacting with PEGS. Users can chat with multimodal content (text and stickers) and will receive multimodal empathetic responses. Left: a conversation characterized by positive emotion (happiness). Right: a conversation characterized by negative emotion (sadness).</font>
</p>

## :four_leaf_clover: Overview

## Related Work
[SER30K: A Large-Scale Dataset for Sticker Emotion Recognition](https://dl.acm.org/doi/10.1145/3503161.3548407)

[Llava-v1: Visual Instruction Tuning](http://arxiv.org/abs/2304.08485)

[Generative Agents: Interactive Simulacra of Human Behavior](http://arxiv.org/abs/2304.03442)
 
